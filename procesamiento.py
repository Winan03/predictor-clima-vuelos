import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from datetime import datetime, timezone, timedelta
import requests
import json
from dotenv import load_dotenv
import os

# Cargar variables del archivo .env
load_dotenv()

# Obtener la API KEY
API_KEY = os.getenv("OPENWEATHER_API_KEY")

if API_KEY:
    print("âœ… Clave cargada correctamente:", API_KEY[:5] + "..." + API_KEY[-5:])
else:
    print("âŒ No se pudo cargar la clave")

def cargar_datos_s3(url_dataset):
    """
    Carga datos desde S3 usando URL pÃºblica
    
    Args:
        url_dataset (str): URL del dataset en S3
    
    Returns:
        pandas.DataFrame: Dataset cargado
    """
    try:
        # Para CSV
        if url_dataset.endswith('.csv'):
            df = pd.read_csv(url_dataset)
        # Para JSON
        elif url_dataset.endswith('.json'):
            response = requests.get(url_dataset)
            data = response.json()
            df = pd.DataFrame(data)
        # Para Excel
        elif url_dataset.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(url_dataset)
        else:
            raise ValueError("Formato de archivo no soportado")
        
        print(f"Dataset cargado exitosamente: {df.shape[0]} filas, {df.shape[1]} columnas")
        return df
    
    except Exception as e:
        print(f"Error cargando datos desde S3: {e}")
        return None

def generar_etiqueta_retraso(df):
    score = (
        0.3 * (df['precipitacion'] > 5) +
        0.2 * (df['viento_velocidad'] > 25) +
        0.1 * ((df['temperatura'] < 5) | (df['temperatura'] > 35)) +
        0.2 * (df['presion'] < 1000) +
        0.2 * (df['visibilidad'] < 5)
    )
    return (score > 0.5).astype(int)


def adaptar_dataset_real(df):
    """
    Adapta el dataset meteorolÃ³gico real al formato esperado por el modelo
    
    Args:
        df (pandas.DataFrame): Dataset con columnas: date,tavg,tmin,tmax,prcp,snow,wdir,wspd,wpgt,pres,tsun
    
    Returns:
        pandas.DataFrame: Dataset adaptado
    """
    df_adaptado = df.copy()

    # Renombrar columnas para que coincidan con el pipeline
    renombres = {
        'date': 'fecha',
        'tavg': 'temperatura',        # Temperatura promedio
        'prcp': 'precipitacion',      # PrecipitaciÃ³n
        'wspd': 'viento_velocidad',   # Velocidad del viento
        'pres': 'presion',            # PresiÃ³n atmosfÃ©rica
        'tmin': 'temperatura_min',    # Temperatura mÃ­nima (adicional)
        'tmax': 'temperatura_max',    # Temperatura mÃ¡xima (adicional)
        'wdir': 'direccion_viento',   # DirecciÃ³n del viento
        'wpgt': 'rafaga_viento',      # RÃ¡faga de viento
        'tsun': 'horas_sol'           # Horas de sol
    }
    
    # Renombrar solo las columnas que existen
    columnas_existentes = {k: v for k, v in renombres.items() if k in df_adaptado.columns}
    df_adaptado = df_adaptado.rename(columns=columnas_existentes)

    # Convertir fecha a datetime
    if 'fecha' in df_adaptado.columns:
        df_adaptado['fecha'] = pd.to_datetime(df_adaptado['fecha'])

    # Rellenar valores faltantes con estrategias especÃ­ficas
    if 'temperatura' in df_adaptado.columns:
        df_adaptado['temperatura'] = df_adaptado['temperatura'].fillna(df_adaptado['temperatura'].mean())
    
    if 'precipitacion' in df_adaptado.columns:
        df_adaptado['precipitacion'] = df_adaptado['precipitacion'].fillna(0)
    
    if 'viento_velocidad' in df_adaptado.columns:
        df_adaptado['viento_velocidad'] = df_adaptado['viento_velocidad'].fillna(0)
    
    if 'presion' in df_adaptado.columns:
        df_adaptado['presion'] = df_adaptado['presion'].fillna(df_adaptado['presion'].mean())

    # Crear columnas derivadas que faltan en el dataset original
    # Humedad estimada (basada en temperatura y precipitaciÃ³n)
    if 'temperatura' in df_adaptado.columns and 'precipitacion' in df_adaptado.columns:
        # FÃ³rmula empÃ­rica para estimar humedad
        df_adaptado['humedad'] = np.clip(
            70 + (df_adaptado['precipitacion'] * 5) - (df_adaptado['temperatura'] - 20) * 2 + np.random.normal(0, 5, len(df_adaptado)),
            30, 95
        )
    else:
        df_adaptado['humedad'] = 65  # Valor por defecto

    # Visibilidad estimada (inversamente relacionada con precipitaciÃ³n)
    if 'precipitacion' in df_adaptado.columns:
        df_adaptado['visibilidad'] = np.clip(
            15 - (df_adaptado['precipitacion'] * 0.8) + np.random.normal(0, 1, len(df_adaptado)),
            1, 15
        )
    else:
        df_adaptado['visibilidad'] = 12  # Valor por defecto

    # Nubosidad estimada (relacionada con precipitaciÃ³n y horas de sol)
    if 'precipitacion' in df_adaptado.columns:
        if 'horas_sol' in df_adaptado.columns:
            # Si tenemos horas de sol, usarlas
            df_adaptado['nubosidad'] = np.clip(
                100 - (df_adaptado['horas_sol'].fillna(6) * 8) + (df_adaptado['precipitacion'] * 15),
                0, 100
            )
        else:
            # Solo basada en precipitaciÃ³n
            df_adaptado['nubosidad'] = np.clip(
                30 + (df_adaptado['precipitacion'] * 20) + np.random.normal(0, 15, len(df_adaptado)),
                0, 100
            )
    else:
        df_adaptado['nubosidad'] = 40  # Valor por defecto

    # LÃ“GICA determinista basada en condiciones climÃ¡ticas
    df_adaptado['retraso_vuelo'] = generar_etiqueta_retraso(df_adaptado)

    print(f"Dataset adaptado: {len(df_adaptado)} registros")
    print(f"Tasa de retrasos generada: {df_adaptado['retraso_vuelo'].mean()*100:.1f}%")
    print(f"Columnas disponibles: {list(df_adaptado.columns)}")

    return df_adaptado

def procesar_datos_clima(df):
    """
    Procesa y limpia los datos climÃ¡ticos reales
    
    Args:
        df (pandas.DataFrame): Dataset crudo con datos meteorolÃ³gicos
    
    Returns:
        pandas.DataFrame: Dataset procesado
    """
    try:
        # Primero adaptar el dataset real al formato esperado
        df_procesado = adaptar_dataset_real(df)
        
        # Crear features adicionales de tiempo si hay columna fecha
        if 'fecha' in df_procesado.columns:
            df_procesado['hora'] = df_procesado['fecha'].dt.hour
            df_procesado['dia_semana'] = df_procesado['fecha'].dt.weekday
            df_procesado['mes'] = df_procesado['fecha'].dt.month
            df_procesado['es_fin_semana'] = (df_procesado['dia_semana'] >= 5).astype(int)
        
        # Crear features de condiciones extremas basadas en datos reales
        if 'precipitacion' in df_procesado.columns:
            df_procesado['lluvia_fuerte'] = (df_procesado['precipitacion'] > 5).astype(int)
        
        if 'viento_velocidad' in df_procesado.columns:
            df_procesado['viento_fuerte'] = (df_procesado['viento_velocidad'] > 20).astype(int)
        
        if 'visibilidad' in df_procesado.columns:
            df_procesado['baja_visibilidad'] = (df_procesado['visibilidad'] < 8).astype(int)
        
        # Manejo mÃ¡s robusto de valores faltantes
        columnas_numericas = df_procesado.select_dtypes(include=[np.number]).columns
        
        for col in columnas_numericas:
            if col != 'retraso_vuelo':  # No imputar la variable objetivo
                # Usar mediana para valores mÃ¡s robustos
                df_procesado[col] = df_procesado[col].fillna(df_procesado[col].median())
        
        # Eliminar outliers extremos (no todos, solo los mÃ¡s extremos)
        df_procesado = eliminar_outliers_extremos(df_procesado, columnas_numericas)
        
        print(f"Datos procesados: {df_procesado.shape[0]} filas despuÃ©s del procesamiento")
        print(f"Columnas finales: {list(df_procesado.columns)}")
        
        return df_procesado
    
    except Exception as e:
        print(f"Error procesando datos: {e}")
        import traceback
        traceback.print_exc()
        return df

def eliminar_outliers_extremos(df, columnas_numericas, max_eliminar=0.3):
    """
    Elimina solo outliers extremos usando un rango mÃ¡s amplio del IQR,
    y evita eliminar mÃ¡s del `max_eliminar`% del dataset.

    Args:
        df (pandas.DataFrame): DataFrame a procesar
        columnas_numericas (list): Lista de columnas numÃ©ricas
        max_eliminar (float): ProporciÃ³n mÃ¡xima de filas que se pueden eliminar (ej. 0.3 = 30%)

    Returns:
        pandas.DataFrame: DataFrame filtrado
    """
    df_limpio = df.copy()
    filas_originales = len(df_limpio)
    mask_total = pd.Series(True, index=df_limpio.index)

    for col in columnas_numericas:
        if col != 'retraso_vuelo':
            Q1 = df_limpio[col].quantile(0.25)
            Q3 = df_limpio[col].quantile(0.75)
            IQR = Q3 - Q1
            lim_inf = Q1 - 3.0 * IQR
            lim_sup = Q3 + 3.0 * IQR
            mask_col = (df_limpio[col] >= lim_inf) & (df_limpio[col] <= lim_sup)
            mask_total &= mask_col

    # Aplicar mÃ¡scara si no elimina mÃ¡s del % permitido
    filas_filtradas = mask_total.sum()
    if filas_filtradas < (1 - max_eliminar) * filas_originales:
        print("âš ï¸ Demasiadas filas serÃ­an eliminadas como outliers. Se omite el filtrado.")
        return df  # devolver sin eliminar
    else:
        df_limpio = df_limpio[mask_total]
        print(f"Outliers eliminados: {filas_originales - len(df_limpio)} filas ({(1 - len(df_limpio)/filas_originales)*100:.1f}%)")
        return df_limpio

def preparar_features(df, columnas_target=['retraso_vuelo'], scaler=None, label_encoders=None):
    """
    Prepara features para entrenamiento o predicciÃ³n del modelo con datos reales
    CORREGIDO: Maneja consistencia de columnas entre entrenamiento y predicciÃ³n

    Args:
        df (pandas.DataFrame): Dataset procesado
        columnas_target (list): Columnas objetivo (solo en entrenamiento)
        scaler (StandardScaler): Escalador entrenado (opcional)
        label_encoders (dict): Diccionario de LabelEncoders entrenados (opcional)

    Returns:
        tuple: (X, y, scaler, label_encoders, feature_names)
    """
    try:
        df_features = df.copy()
        print(f"DataFrame de entrada - Shape: {df_features.shape}")
        print(f"Columnas disponibles: {list(df_features.columns)}")

        # Definir columnas esperadas por el modelo (solo las que estaban en entrenamiento)
        # Estas son las columnas bÃ¡sicas que debe tener el modelo
        columnas_esperadas = [
            'temperatura', 'precipitacion', 'viento_velocidad', 'presion',
            'humedad', 'visibilidad', 'nubosidad',
            'hora', 'dia_semana', 'mes', 'es_fin_semana',
            'lluvia_fuerte', 'viento_fuerte'
        ]

        # Si es modo predicciÃ³n y tenemos scaler, usar sus feature names
        if scaler is not None:
            if hasattr(scaler, 'feature_names_in_'):
                columnas_esperadas = list(scaler.feature_names_in_)
                print(f"Usando columnas del scaler entrenado: {columnas_esperadas}")
            else:
                print("âš ï¸ El scaler no tiene 'feature_names_in_'. Usando columnas por defecto.")

        # Asegurar que tenemos todas las columnas esperadas
        for col in columnas_esperadas:
            if col not in df_features.columns:
                print(f"Advertencia: Columna {col} no encontrada, usando valor por defecto")
                if col == 'temperatura':
                    df_features[col] = 22.0
                elif col == 'precipitacion':
                    df_features[col] = 0.0
                elif col == 'viento_velocidad':
                    df_features[col] = 10.0
                elif col == 'presion':
                    df_features[col] = 1013.25
                elif col == 'hora':
                    df_features[col] = 12
                elif col == 'dia_semana':
                    df_features[col] = 1
                elif col == 'mes':
                    df_features[col] = 6
                elif col == 'es_fin_semana':
                    df_features[col] = 0
                elif col == 'lluvia_fuerte':
                    df_features[col] = 0
                elif col == 'viento_fuerte':
                    df_features[col] = 0
                else:
                    df_features[col] = 0

        # Separar features y target
        columnas_a_eliminar = ['fecha']
        
        # Solo eliminar columnas target si existen
        for col_target in columnas_target:
            if col_target in df_features.columns:
                columnas_a_eliminar.append(col_target)
        
        # Eliminar columnas que no estÃ¡n en el conjunto esperado
        columnas_a_mantener = columnas_esperadas.copy()
        
        # Si hay columnas target, aÃ±adirlas temporalmente
        for col_target in columnas_target:
            if col_target in df_features.columns:
                columnas_a_mantener.append(col_target)
        
        # Filtrar solo las columnas que necesitamos
        df_filtrado = df_features[columnas_a_mantener].copy()
        
        # Separar X e y
        X = df_filtrado.drop(columnas_target, axis=1, errors='ignore')
        
        # Reordenar columnas segÃºn el orden esperado
        X = X[columnas_esperadas]
        
        # Solo extraer y si la columna target existe
        y = None
        if columnas_target and columnas_target[0] in df_filtrado.columns:
            y = df_filtrado[columnas_target[0]]

        print(f"Columnas finales de X: {list(X.columns)}")
        print(f"Shape de X despuÃ©s del filtrado: {X.shape}")

        # Verificar tipos de datos y convertir todo a numÃ©rico
        for col in X.columns:
            if X[col].dtype == 'object':
                print(f"Convirtiendo columna {col} a numÃ©rica")
                # Si hay un label encoder para esta columna, usarlo
                if label_encoders and col in label_encoders:
                    le = label_encoders[col]
                    try:
                        X[col] = le.transform(X[col].astype(str))
                    except ValueError:
                        # Valores no vistos, usar valor por defecto
                        X[col] = 0
                else:
                    # Convertir directamente a numÃ©rico
                    X[col] = pd.to_numeric(X[col], errors='coerce').fillna(0)

        # Verificar que no hay valores NaN
        if X.isnull().any().any():
            print("Rellenando valores NaN con 0")
            X = X.fillna(0)
        
        # Verificar que no hay valores infinitos
        if np.isinf(X.values).any():
            print("Reemplazando valores infinitos")
            X = X.replace([np.inf, -np.inf], 0)

        # Escalar variables numÃ©ricas
        if scaler is None:
            # Modo entrenamiento - crear nuevo scaler
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            X = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)
        else:
            # Modo predicciÃ³n - usar scaler existente
            try:
                X_scaled = scaler.transform(X)
                X = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)
            except Exception as e:
                print(f"Error en escalado: {e}")
                return None, None, None, None, None

        print(f"Shape final de X: {X.shape}")
        print(f"Columnas finales: {list(X.columns)}")
        
        return X, y, scaler, label_encoders, list(X.columns)

    except Exception as e:
        print(f"Error preparando features: {e}")
        import traceback
        traceback.print_exc()
        return None, None, None, None, None

def diagnostico_features_antes_del_escalado(df):
    """
    Muestra estadÃ­sticas bÃ¡sicas de las features clave antes del escalado.
    """
    columnas_interes = ['humedad', 'visibilidad', 'nubosidad']
    print("\nğŸ“Š EstadÃ­sticas bÃ¡sicas antes del escalado:")
    for col in columnas_interes:
        if col in df.columns:
            print(f"\nğŸ”¹ {col.upper()}:")
            print(df[col].describe())
        else:
            print(f"âš ï¸ La columna '{col}' no estÃ¡ presente en el DataFrame.")

def analizar_aporte_nuevas_features(self, columnas=['humedad', 'visibilidad', 'nubosidad']):
    """
    Imprime la importancia de las nuevas variables si el modelo lo permite.
    """
    if hasattr(self.modelo, 'feature_importances_'):
        print("\nğŸ¯ Importancia de nuevas features climÃ¡ticas:")
        importancias = self.modelo.feature_importances_
        for col, imp in zip(self.scaler.feature_names_in_, importancias):
            if col in columnas:
                print(f"ğŸ” {col}: {imp:.4f}")
    else:
        print("âš ï¸ El modelo seleccionado no soporta anÃ¡lisis de importancia de variables.")

def validar_calidad_datos(df):
    """
    Valida la calidad de los datos meteorolÃ³gicos reales
    
    Args:
        df (pandas.DataFrame): Dataset a validar
    
    Returns:
        dict: Reporte de calidad de datos
    """
    reporte = {
        'total_filas': len(df),
        'total_columnas': len(df.columns),
        'valores_faltantes': df.isnull().sum().to_dict(),
        'tipos_datos': df.dtypes.to_dict(),
        'duplicados': df.duplicated().sum(),
    }
    
    # Solo incluir estadÃ­sticas para columnas numÃ©ricas que existen
    columnas_numericas = df.select_dtypes(include=[np.number]).columns
    if len(columnas_numericas) > 0:
        reporte['estadisticas_numericas'] = df[columnas_numericas].describe().to_dict()
    
    # Calcular porcentaje de valores faltantes
    reporte['porcentaje_faltantes'] = {
        col: (count / len(df)) * 100 
        for col, count in reporte['valores_faltantes'].items()
    }
    
    # Reporte especÃ­fico para datos meteorolÃ³gicos
    if 'temperatura' in df.columns:
        reporte['rango_temperatura'] = {
            'min': df['temperatura'].min(),
            'max': df['temperatura'].max(),
            'promedio': df['temperatura'].mean()
        }
    
    if 'precipitacion' in df.columns:
        reporte['dias_lluvia'] = (df['precipitacion'] > 0).sum()
        reporte['precipitacion_maxima'] = df['precipitacion'].max()
    
    if 'retraso_vuelo' in df.columns:
        reporte['tasa_retrasos'] = df['retraso_vuelo'].mean() * 100
        reporte['total_retrasos'] = df['retraso_vuelo'].sum()
    
    return reporte

def obtener_datos_clima_reales(ciudad, fecha=None, hora=None):
    """
    Obtiene datos climÃ¡ticos futuros (si se especifica fecha y hora) o actuales (por defecto) de OpenWeather.

    Args:
        ciudad (str): Nombre de la ciudad
        fecha (str): Fecha en formato YYYY-MM-DD (opcional)
        hora (str): Hora en formato HH:MM (opcional)

    Returns:
        dict: Diccionario con variables climÃ¡ticas clave
    """
    if not API_KEY:
        print("âŒ No se encontrÃ³ la clave API de OpenWeather.")
        return {}

    try:
        # Si se da fecha y hora, usar API de pronÃ³stico
        if fecha and hora:
            print("ğŸ“… Solicitando clima pronosticado...")
            url = f"http://api.openweathermap.org/data/2.5/forecast?q={ciudad}&appid={API_KEY}&units=metric"
            target_dt = datetime.strptime(f"{fecha} {hora}", "%Y-%m-%d %H:%M")
        else:
            print("ğŸ“ Solicitando clima actual...")
            url = f"http://api.openweathermap.org/data/2.5/weather?q={ciudad}&appid={API_KEY}&units=metric"
            target_dt = None

        response = requests.get(url)
        data = response.json()

        if response.status_code != 200:
            print("âŒ Error en respuesta de OpenWeather:", data)
            return {}

        # Si se usa pronÃ³stico
        if 'list' in data:
            forecast_data = data['list']
            closest_block = min(forecast_data, key=lambda x: abs(datetime.utcfromtimestamp(x['dt']) - target_dt))
            block = closest_block
        else:
            block = data  # clima actual

        # Extraer datos comunes
        temperatura = block['main']['temp']
        humedad = block['main']['humidity']
        presion = block['main']['pressure']
        visibilidad = block.get('visibility', 10000)  # en metros
        viento_velocidad = block['wind']['speed']
        nubosidad = block['clouds']['all']
        
        # Detectar precipitaciÃ³n real (si existe el campo rain)
        rain_data = block.get('rain', {})
        if 'list' in data:
            precipitacion = rain_data.get('3h', 0.0)  # PronÃ³stico
        else:
            precipitacion = rain_data.get('1h', 0.0)  # Clima actual

        # Imprimir para depurar
        if rain_data:
            print(f"ğŸŒ§ï¸ Lluvia detectada: {rain_data}")
        else:
            print("ğŸŒ¤ï¸ No hay campo de lluvia (rain). Se asume 0 mm.")

        # Timestamp
        timestamp = block.get('dt')
        dt_utc = datetime.fromtimestamp(timestamp, tz=timezone.utc) if timestamp else None
        dt_peru = dt_utc - timedelta(hours=5) if dt_utc else None

        # === ğŸ” TRAZABILIDAD (para verificar que corresponde con lo pedido) ===
        print("\nğŸ§ª VERIFICACIÃ“N DE PRONÃ“STICO")
        print(f"ğŸŒ Ciudad solicitada: {ciudad}")
        print(f"ğŸ“† Fecha objetivo enviada: {fecha}")
        print(f"â° Hora objetivo enviada: {hora}")
        print(f"ğŸ•’ Fecha/hora solicitada: {target_dt}")
        print(f"ğŸ•“ Fecha/hora real del pronÃ³stico (UTC): {dt_utc}")
        print(f"ğŸ•“ Fecha/hora real del pronÃ³stico (PerÃº): {dt_peru}")
        print(f"ğŸ“¦ Datos del bloque mÃ¡s cercano:")
        print(json.dumps(block, indent=2))

        clima = {
            'temperatura': round(temperatura, 1),
            'humedad': humedad,
            'presion': presion,
            'visibilidad': round(visibilidad / 1000, 1),  # a km
            'viento_velocidad': round(viento_velocidad * 3.6, 1),  # m/s â†’ km/h
            'nubosidad': nubosidad,
            'precipitacion': precipitacion,
            'fecha_observacion_utc': dt_utc.strftime('%Y-%m-%d %H:%M:%S UTC') if dt_utc else 'N/A',
            'fecha_observacion_peru': dt_peru.strftime('%Y-%m-%d %H:%M:%S (UTC-5)') if dt_peru else 'N/A',
            'fecha_predicha_openweather_utc': dt_utc.strftime('%Y-%m-%d %H:%M:%S') if dt_utc else 'N/A',
            'ciudad': ciudad,
            'fecha_solicitada': fecha,
            'hora_solicitada': hora
        }

        print("ğŸ” JSON recibido de OpenWeather:", json.dumps(block, indent=2))

        return clima

    except Exception as e:
        print(f"âš ï¸ Error al obtener datos climÃ¡ticos: {e}")
        return {}

if __name__ == "__main__":
    ciudad = "Cajamarca"
    clima = obtener_datos_clima_reales(ciudad)
    print(f"ğŸŒ¦ï¸ Clima actual en {ciudad}: {clima}")
